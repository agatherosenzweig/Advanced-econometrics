{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.optimize import minimize_scalar\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I - GMM/IV "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Andersen and Hsiao, 1981, 1982)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simulation of the data\n",
    "random.seed(2040)\n",
    "n= 100\n",
    "T= 5\n",
    "phizero=0.4\n",
    "\n",
    "#definition of y0 for the n individuals \n",
    "a = np.random.normal(0,1, size = n)\n",
    "y0 = np.vectorize(lambda x: np.random.normal(x/(1-phizero),1/np.sqrt(1-phizero**2)))(a)\n",
    "epsilon = np.random.normal(0, 1, size = n*T)\n",
    "\n",
    "\n",
    "#matrix where each row is the time period, and each column is the ith individual\n",
    "y=np.zeros((T+1,n))\n",
    "\n",
    "#the first row of the matrix is y0\n",
    "y[0] = y0\n",
    "\n",
    "delta_y = np.zeros((T,n))\n",
    "delta_epsilon = np.zeros((T,n))\n",
    "\n",
    "#recursive definition of y, delta_y and delta_epsilon\n",
    "for j in tqdm.tqdm(range(1,T+1)):\n",
    "    y[j] = a + y[j-1]*phizero + epsilon[j]\n",
    "    delta_y[j-1] = y[j] - y[j-1]\n",
    "    delta_epsilon[j-1] = epsilon[j] - epsilon[j-1]\n",
    "    \n",
    "\n",
    "def moments(phizero): \n",
    "    moments = []\n",
    "    Z = np.zeros(((T-2,n)))\n",
    "    \n",
    "    for s in tqdm.tqdm(range(2, T)):\n",
    "        t = 3\n",
    "        while t - s <= t - 1:\n",
    "                moments.append(sum(y[t-s][i]*phizero*delta_y[t-2][i]+ delta_epsilon[t-1][i] for i in range(0,n)))\n",
    "    return(moments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moments(0.4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the empirical counterpart of the moment condition (5), p69\n",
    "\n",
    "$$ \\frac{1}{N}\\sum_{i=1}^N y_{it-s}(\\Delta y_{i,t-1}) = 0 $$\n",
    "\n",
    "Where  $s \\in \\{2, ..., t-1 \\}$ thus $ \\forall t \\geq 3$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis on a : \n",
    "$h(\\rho,Y_i,Z_i,X_i) = (h(\\rho,\\Delta y_{11},z_{1T}),h(\\rho,\\Delta y_{21},z_{2T})...)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalement on minimise le critère : \n",
    "    $$Q(\\theta)=[\\sum_{i=1}^Nh_i(\\theta,Y_i)]'W_T[\\sum_{i=1}^Nh(\\theta,Y_i)]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On agrège tous les moments d'un individu donné dans un vecteur \n",
    "def tab_h(i,rho):\n",
    "    tab_h=[]\n",
    "    for t in range(1,T-1):\n",
    "        tab_h+=h(rho,i,t)\n",
    "    return np.array(tab_h)\n",
    "\n",
    "#On définit le critère ci dessus.\n",
    "def critere(rho):\n",
    "    M=1/(n-1)*sum([tab_h(i,rho) for i in range(n-1)])\n",
    "    return M@M.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 0.15289905480514548\n",
       "    nfev: 9\n",
       "     nit: 5\n",
       " success: True\n",
       "       x: 0.846562269178982"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimize_scalar(critere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_i,t = alpha_i + varepsilon_i,t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après trop de temps à me perdre dans l'article de Arellano Bover 95 (pour qqch de vraiment pas ouf), j'ai enfin compris que Arrelo Bover ajoute comme nouveaux moments à rajouter dans le GMM. J'ai trouvé cette version clair de ça dans Blundell bond 98 :\n",
    "$$ E(u_{i,t},\\Delta y_{i,t-1})=E((y_{i,t}-\\phi_0 y_{it-1})(y_{i,t-1}-y_{it-2})=0, \\text{for } t=2,3,...,T $$\n",
    "\n",
    "Genre les résidu de l'équation au temps t sont orthogonaux de leur \"condition intiale\" au temps t-1.\n",
    "\n",
    "On va coder ça. Comme il y qu'un seul momen par temps c'est plus facile, on les mets direct dans un vecteur pour chaque individu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moment_l (i,rho):\n",
    "    moment_l=[]\n",
    "    for t in range(3,T):\n",
    "        moment_l+=[(y[i,t]-rho*y[i,t-1])*(y[i,t-1]-y[i,t-2])] \n",
    "    return moment_l\n",
    "\n",
    "\n",
    "def GMM_Ar_Bond (rho) :\n",
    "    moments=[]\n",
    "    for i in range(n):\n",
    "        moments.append(np.array(moment_l(i,rho)+list(tab_h(i,rho))))\n",
    "    M=1/(n-1)*sum([moments[i] for i in range(n-1)])\n",
    "    return M@M.T\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 0.18093396871093076\n",
       "    nfev: 9\n",
       "     nit: 5\n",
       " success: True\n",
       "       x: 0.7668950057455812"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimize_scalar(GMM_Ar_Bond)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bon pour l'instant je sais pas pourquoi mais les résultats sont absolument pas ouf XD. Je pense que si on remettait tout ca en forme matricielle et qu'on fait juste la formule ca fonctionnerait mieux :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Approche Han et Phillips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation directe:  0.5083157687270698\n",
      "Estimation par algo:  -7.033631747419856\n"
     ]
    }
   ],
   "source": [
    "#Implémentation directe\n",
    "numerateur=0\n",
    "denominateur=0\n",
    "for i in range(n) :\n",
    "    for t in range(T):\n",
    "        delta_1=y[i,t-1]-y[i,t-2]\n",
    "        delta=y[i,t]-y[i,t-1]\n",
    "        numerateur+=delta_1*(2*delta+delta_1)\n",
    "        denominateur+=(delta_1)**2\n",
    "\n",
    "estim=numerateur/denominateur\n",
    "print(\"Estimation directe: \",estim)\n",
    "\n",
    "#implémentation par algo de maximisation\n",
    "def moment_HP(i,rho):\n",
    "    moment_l=[]\n",
    "    for t in range(3,T):\n",
    "        delta_1=y[i,t-1]-y[i,t-2]\n",
    "        delta=y[i,t]-y[i,t-1]\n",
    "        moment_l+=[delta_1*(2*delta+delta_1)-rho*delta_1] \n",
    "    return moment_l\n",
    "\n",
    "def GMM_HP(rho):\n",
    "    moments=[]\n",
    "    for i in range(n):\n",
    "        moments.append(np.array(moment_HP(i,rho)))\n",
    "    M=1/(n-1)*sum([moments[i] for i in range(n-1)])\n",
    "    return M@M.T\n",
    "\n",
    "estim2=minimize_scalar(GMM_HP, tol=0.01)\n",
    "print(\"Estimation par algo: \",estim2[\"x\"])  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLE avec correction de biais de Han et Kuersteiner : la formule explicite est donnée directe dans l'article : je recopie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37619122231607705\n"
     ]
    }
   ],
   "source": [
    "within_ = [1/T*sum([y[i][t-1] for t in range(1,T)]) for i in range(n)]\n",
    "within = [1/T*sum([y[i][t] for t in range(1,T)]) for i in range(n)]\n",
    "\n",
    "#Denominateur (le même pour OLS et HK, noté Upsilon):\n",
    "Upsilon=0\n",
    "for i in range(n):\n",
    "    for t in range(1,T):\n",
    "        Upsilon+=(y[i,t-1]-within_[i])**2\n",
    "        \n",
    "Upsilon*=1/(n*T)\n",
    "\n",
    "#Numérateur (le même pour OLS et la première partie de HK)\n",
    "HK_num_1=0\n",
    "for i in range(n):\n",
    "    for t in range(1,T):\n",
    "        HK_num_1+=(y[i,t-1]-within_[i])*(y[i,t]-within_[i])\n",
    "HK_num_1*=1/(n*T)\n",
    "\n",
    "phi_OLS=HK_num_1/Upsilon\n",
    "\n",
    "omega=(1-phi_OLS**2)*Upsilon\n",
    "\n",
    "HK_num_2 = (1/T)*(1-phi_OLS)*omega\n",
    "\n",
    "HK_estim=(HK_num_1+HK_num_2)/Upsilon\n",
    "\n",
    "print(HK_estim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mnt il faut coder l'inférence indirecte :\n",
    "\n",
    "1) On crée une fonction qui génère des données avec un phi donné\n",
    "\n",
    "2) On crée une fonction qui calcul OLS avec des données donnée\n",
    "\n",
    "3) On utilise la super fonction trop cool qui minimise des fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exactement la même chose qu'au début\n",
    "random.seed(2040)\n",
    "def gener_donne(phi,n,T):\n",
    "    phizero=float(phi)\n",
    "    a=np.array([np.random.normal(0,1) for i in range(n)])\n",
    "    y0=np.array([np.random.normal(a[i]/(1-phizero),1/np.sqrt(1-phizero**2)) for i in range(n)])\n",
    "    epsilon=[np.random.normal(0,1) for i in range(n*T)]\n",
    "    y=np.zeros((T,n))\n",
    "    y[0]=y0\n",
    "    y=y.T\n",
    "    for i in range(n):\n",
    "        for j in range(1,T):\n",
    "            y[i][j]=a[i]+phizero*y[i][j-1]+epsilon[i*T+j]\n",
    "    \n",
    "    return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Formule du papier pour l'estimateur\n",
    "def ML_papier(y):\n",
    "    mat_y_=y[:,:T-1]\n",
    "    mat_y=y[:,1:]\n",
    "    \n",
    "    y=mat_y.reshape(n*(T-1),1)\n",
    "    y_=mat_y_.reshape(n*(T-1),1)\n",
    "        \n",
    "    phi_ML_aux=np.linalg.inv((y_.T)@y_)@((y_.T)@y)\n",
    "    \n",
    "    return phi_ML_aux\n",
    "\n",
    "#Calcul de la binding function simulée pour un phi donnée\n",
    "def b_NT(phi,H):\n",
    "    b_simul=[ML_papier(gener_donne(phi,n,T)) for H in range(H)]\n",
    "    return np.mean(b_simul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: array([[0.00032135]])\n",
       " message: 'Solution found.'\n",
       "    nfev: 18\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([[0.41676448]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Minimisation de l'écart entre la binding fuction simulée et la \"vraie valeur\"\n",
    "# de la binding function\n",
    "\n",
    "def estim_indirect(H):\n",
    "    x=ML_papier(y)\n",
    "    def ecartL2(phi):\n",
    "        return abs(x-b_NT(phi,H))\n",
    "    return minimize_scalar(ecartL2,method=\"bounded\", bounds=(0.01,0.99) )\n",
    "\n",
    "\n",
    "estim_indirect(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
